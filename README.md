# ğŸ”¢ MNIST Handwritten Digit Recognition

A classic "Hello World" deep learning project that trains a **Convolutional Neural Network (CNN)** to classify handwritten digits (0-9) using the MNIST dataset.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## âœ¨ Features

- ğŸ§  **Modern CNN Architecture** - BatchNorm, Dropout, and 3 convolutional layers
- ğŸ“Š **Training Pipeline** - Complete with validation, metrics, and model checkpointing
- ğŸ¨ **Interactive Demo** - Draw digits and get real-time predictions via Gradio
- ğŸ“ˆ **Visualizations** - Training curves, confusion matrix, and sample predictions
- ğŸš€ **High Accuracy** - Achieves ~99% accuracy on MNIST test set

## ğŸ—ï¸ Project Structure

```
CNN/
â”œâ”€â”€ requirements.txt    # Project dependencies
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ model.py            # CNN architecture definition
â”œâ”€â”€ train.py            # Training script
â”œâ”€â”€ predict.py          # Inference/prediction utilities
â”œâ”€â”€ utils.py            # Helper functions
â”œâ”€â”€ demo.py             # Gradio interactive demo
â”œâ”€â”€ models/             # Saved model checkpoints
â”‚   â”œâ”€â”€ mnist_cnn.pth
â”‚   â””â”€â”€ mnist_cnn_best.pth
â””â”€â”€ outputs/            # Training visualizations
    â”œâ”€â”€ training_curves.png
    â”œâ”€â”€ confusion_matrix.png
    â””â”€â”€ sample_predictions.png
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train the Model

```bash
python train.py
```

This will:
- Download the MNIST dataset automatically
- Train the CNN for 10 epochs
- Save the best model to `models/mnist_cnn_best.pth`
- Generate visualizations in the `outputs/` folder

**Training Options:**
```bash
python train.py --epochs 20 --batch-size 128 --lr 0.0005
```

### 3. Launch Interactive Demo

```bash
python demo.py
```

Open your browser to `http://127.0.0.1:7860` and draw digits!

### 4. Test Predictions

```bash
python predict.py
```

## ğŸ§  Model Architecture

```
Input (1, 28, 28) - Grayscale 28Ã—28 image
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv Block 1                           â”‚
â”‚  Conv2D(1â†’32, 3Ã—3) â†’ BatchNorm â†’ ReLU   â”‚
â”‚  MaxPool(2Ã—2) â†’ Dropout(0.25)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv Block 2                           â”‚
â”‚  Conv2D(32â†’64, 3Ã—3) â†’ BatchNorm â†’ ReLU  â”‚
â”‚  MaxPool(2Ã—2) â†’ Dropout(0.25)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv Block 3                           â”‚
â”‚  Conv2D(64â†’128, 3Ã—3) â†’ BatchNorm â†’ ReLU â”‚
â”‚  MaxPool(2Ã—2) â†’ Dropout(0.25)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fully Connected Layers                 â”‚
â”‚  Flatten â†’ FC(1152â†’256) â†’ ReLU          â”‚
â”‚  Dropout(0.5) â†’ FC(256â†’128) â†’ ReLU      â”‚
â”‚  FC(128â†’10)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Output (10) - Logits for each digit class
```

**Model Statistics:**
- Parameters: ~300,000
- Model Size: ~1.2 MB
- Inference Time: <1ms on GPU, ~5ms on CPU

## ğŸ“Š Results

| Metric | Value |
|--------|-------|
| Training Accuracy | ~99.5% |
| Validation Accuracy | ~99.0% |
| Training Time (GPU) | ~2-3 minutes |
| Training Time (CPU) | ~15-20 minutes |

### Sample Outputs

After training, you'll find these visualizations in the `outputs/` folder:

- **Training Curves** - Loss and accuracy over epochs
- **Confusion Matrix** - Classification performance per digit
- **Sample Predictions** - Visual examples with confidence scores

## ğŸ“ Dataset

The [MNIST dataset](http://yann.lecun.com/exdb/mnist/) contains:
- **60,000** training images
- **10,000** test images
- **28Ã—28** grayscale images
- **10 classes** (digits 0-9)

The dataset is downloaded automatically when you run `train.py`.

## ğŸ”§ Configuration

### Training Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--epochs` | 10 | Number of training epochs |
| `--batch-size` | 64 | Batch size for training |
| `--lr` | 0.001 | Learning rate |
| `--no-cuda` | False | Disable GPU acceleration |

### Data Augmentation

The training pipeline includes:
- Random rotation (Â±10Â°)
- Random translation (Â±10%)
- Random scaling (90-110%)

## ğŸ“š API Usage

### Using the Predictor

```python
from predict import MNISTPredictor
from PIL import Image

# Load the predictor
predictor = MNISTPredictor()

# Predict from image file
digit, confidence, probs = predictor.predict("digit.png")
print(f"Predicted: {digit} (Confidence: {confidence:.2%})")

# Predict from PIL Image
image = Image.open("digit.png")
digit, confidence, probs = predictor.predict(image)

# Predict from numpy array
import numpy as np
array = np.array(image)
digit, confidence, probs = predictor.predict(array)
```

### Using the Model Directly

```python
import torch
from model import MNISTNet

# Create model
model = MNISTNet()

# Load trained weights
checkpoint = torch.load('./models/mnist_cnn.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Make prediction
input_tensor = torch.randn(1, 1, 28, 28)
output = model(input_tensor)
predicted = torch.argmax(output, dim=1)
```

## ğŸ› ï¸ Development

### Prerequisites

- Python 3.8+
- CUDA (optional, for GPU acceleration)

### Running Tests

```bash
# Test model architecture
python model.py

# Test prediction module
python predict.py
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/) by Yann LeCun
- [PyTorch](https://pytorch.org/) for the deep learning framework
- [Gradio](https://gradio.app/) for the interactive web interface

---

<p align="center">
  Made with â¤ï¸ for learning deep learning
</p>
