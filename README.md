# ğŸ”¤ Handwritten Character Recognition

A complete deep learning project for **handwritten character recognition** using Convolutional Neural Networks (CNN). Supports **digits**, **letters**, and **full alphanumeric** recognition.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![Accuracy](https://img.shields.io/badge/Accuracy-99%25+-green.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## âœ¨ Features

- ğŸ”¢ **Digits (0-9)** - MNIST dataset, 10 classes
- ğŸ”¤ **Letters (A-Z)** - EMNIST Letters, 26 classes
- ğŸ”£ **Alphanumeric** - EMNIST Balanced, 47 classes
- ğŸ“ **Full Alphanumeric** - EMNIST ByClass, 62 classes (0-9, A-Z, a-z)
- ğŸ¨ **Web Interface** - Upload and classify with Gradio
- ğŸ“¦ **Batch Processing** - Process folders, export to CSV/JSON
- ğŸ““ **Jupyter Notebook** - Step-by-step tutorial
- ğŸš€ **99%+ Accuracy** - Production-ready models

## ğŸ—ï¸ Project Structure

```
CNN/
â”œâ”€â”€ model.py              # Original MNIST CNN (backward compatible)
â”œâ”€â”€ model_extended.py     # Extended CNN for alphanumeric (10-62 classes)
â”œâ”€â”€ train.py              # Original MNIST training
â”œâ”€â”€ train_extended.py     # Unified training for all datasets
â”œâ”€â”€ predict.py            # Original MNIST predictor
â”œâ”€â”€ predict_extended.py   # Extended predictor for all models
â”œâ”€â”€ data_loader.py        # MNIST/EMNIST data utilities
â”œâ”€â”€ utils.py              # Helper functions
â”œâ”€â”€ app.py                # Web interface
â”œâ”€â”€ batch_processor.py    # Batch processing
â”œâ”€â”€ mnist_walkthrough.ipynb  # Tutorial notebook
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ models/               # Trained model checkpoints
â”‚   â”œâ”€â”€ mnist_cnn.pth
â”‚   â”œâ”€â”€ letters_model.pth
â”‚   â”œâ”€â”€ balanced_model.pth
â”‚   â””â”€â”€ byclass_model.pth
â””â”€â”€ data/                 # Datasets (auto-downloaded)
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train Models

```bash
# Digits only (0-9) - fastest
python train_extended.py --dataset mnist --epochs 10

# Letters only (A-Z)
python train_extended.py --dataset letters --epochs 10

# Alphanumeric (47 classes)
python train_extended.py --dataset balanced --epochs 15

# Full Alphanumeric (62 classes) - most comprehensive
python train_extended.py --dataset byclass --epochs 15
```

### 3. Launch Web Interface

```bash
python app.py
```
Open http://127.0.0.1:7860 and select the model type.

## ğŸ“Š Supported Datasets

| Dataset | Classes | Characters | Training Samples |
|---------|---------|------------|------------------|
| **MNIST** | 10 | 0-9 | 60,000 |
| **EMNIST Letters** | 26 | A-Z | 124,800 |
| **EMNIST Balanced** | 47 | 0-9, A-Z, some lowercase | 112,800 |
| **EMNIST ByClass** | 62 | 0-9, A-Z, a-z | 697,932 |

## ğŸ§  Model Architecture

```
Input (1, 28, 28) - Grayscale 28Ã—28 image
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv Block 1: Conv2D(1â†’32) + BN + ReLU â”‚
â”‚  MaxPool(2Ã—2) + Dropout(0.25)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Conv Block 2: Conv2D(32â†’64) + BN + ReLUâ”‚
â”‚  MaxPool(2Ã—2) + Dropout(0.25)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Conv Block 3: Conv2D(64â†’128) + BN      â”‚
â”‚  MaxPool(2Ã—2) + Dropout(0.25)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Conv Block 4: Conv2D(128â†’256) + BN     â”‚
â”‚  Dropout(0.25)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FC: 2304 â†’ 512 â†’ 256 â†’ N classes       â”‚
â”‚  (N = 10, 26, 47, or 62)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Model Size:** ~2-3 MB depending on output classes

## ğŸ“š Usage Examples

### Basic Prediction

```python
from predict_extended import AlphanumericPredictor

# Load specific model
predictor = AlphanumericPredictor(dataset_type='letters')

# Predict
label, index, confidence, probs = predictor.predict("image.png")
print(f"Predicted: {label} ({confidence:.1%})")

# Get top-5 predictions
top5 = predictor.get_top_predictions("image.png", top_k=5)
for char, conf in top5:
    print(f"  {char}: {conf:.1%}")
```

### Batch Processing

```python
from batch_processor import BatchProcessor

processor = BatchProcessor()
results = processor.process_folder("./handwritten_chars/")
processor.save_results_csv()
processor.print_summary()
```

## ğŸ”§ Command Line Options

```bash
python train_extended.py --dataset TYPE --epochs N --batch-size B --lr RATE

# Options:
#   --dataset   : mnist, letters, balanced, byclass
#   --epochs    : Number of training epochs
#   --batch-size: Batch size (default: 64)
#   --lr        : Learning rate (default: 0.001)
#   --no-cuda   : Disable GPU
```

## ğŸ““ Jupyter Notebook

For an interactive tutorial:

```bash
jupyter notebook mnist_walkthrough.ipynb
```

## ğŸ› ï¸ Development

### Test Models

```bash
# Test extended model
python model_extended.py

# Test data loader
python data_loader.py

# Test predictions
python predict_extended.py
```

## ğŸ“„ License

MIT License

---

<p align="center">
  Made with â¤ï¸ for learning deep learning by Ayush Singh
</p>
